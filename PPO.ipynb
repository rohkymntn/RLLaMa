{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_Sa-BPjU0LP",
        "outputId": "7c01a4d6-528a-4c2d-d3cd-49d395839a1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entire model loaded successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-f86f8f179d9d>:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  reward_model = torch.load(\"mol2vecLSTM.pth\", map_location=torch.device('cpu'))\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# ============================\n",
        "# 1. LSTM Reward Model\n",
        "# ============================\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, lstm_size, hidden_size, dropout_rate):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        input_size = 300  # The size of the input vector (embedding size)\n",
        "        out_size = 1      # Predicting a single scalar value (pIC50)\n",
        "\n",
        "        # Define layers\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=lstm_size, num_layers=1, batch_first=True, bidirectional=False)\n",
        "        self.fc1 = nn.Linear(lstm_size, hidden_size)  # Fully connected hidden layer\n",
        "        self.activation = nn.ReLU()                  # Non-linear activation\n",
        "        self.fc_out = nn.Linear(hidden_size, out_size)  # Output layer\n",
        "        self.dropout = nn.Dropout(dropout_rate)       # Dropout layer for regularization\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass\n",
        "        out, (h_n, c_n) = self.lstm(x)  # LSTM: h_n is the last hidden state\n",
        "        out = h_n[-1]                   # Get the last hidden state (LSTM output for the last timestep)\n",
        "        out = self.dropout(out)         # Apply dropout\n",
        "        out = self.fc1(out)             # Pass through the hidden layer\n",
        "        out = self.activation(out)      # Apply ReLU activation\n",
        "        out = self.dropout(out)         # Apply dropout again\n",
        "        out = self.fc_out(out)          # Final output layer\n",
        "        return out\n",
        "\n",
        "reward_model = torch.load(\"mol2vecLSTM.pth\", map_location=torch.device('cpu'))\n",
        "reward_model.eval()\n",
        "\n",
        "print(\"Entire model loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "913d2nn2Mh0S",
        "outputId": "4363fedc-e7a9-4964-e2cf-957394ccd367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token = \"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\"\n",
        "from huggingface_hub import login, logout\n",
        "login(token) # non-blocking login|"
      ],
      "metadata": {
        "id": "iO443DW3WqL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 2. Policy Model (LLM)\n",
        "# ============================\n",
        "policy_model_name = \"vonPipe/jak2InstructSFT\"\n",
        "policy_model = AutoModelForCausalLM.from_pretrained(policy_model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(policy_model_name)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "uHIVzumoU8mq",
        "outputId": "3b356b2e-0344-4eef-fcc1-8f97a254f3de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'AutoModelForCausalLM' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b1525a6436c8>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ============================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpolicy_model_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"vonPipe/jak2InstructSFT\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpolicy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_model_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_model_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'AutoModelForCausalLM' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selfies\n",
        "!pip install rdkit\n",
        "!pip install selfies\n",
        "!pip install deepchem\n",
        "!pip install gensim\n",
        "!pip install torch\n",
        "!pip install git+https://github.com/samoturk/mol2vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrqIMnFlW-Eu",
        "outputId": "309a023f-aff1-4608-f231-e1bed2a11e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selfies in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2024.3.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (11.0.0)\n",
            "Requirement already satisfied: selfies in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Requirement already satisfied: deepchem in /usr/local/lib/python3.10/dist-packages (2.8.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from deepchem) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.5.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.13.1)\n",
            "Requirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.10/dist-packages (from deepchem) (1.13.1)\n",
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (from deepchem) (2024.3.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->deepchem) (2024.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit->deepchem) (11.0.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->deepchem) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->deepchem) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->deepchem) (1.16.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting git+https://github.com/samoturk/mol2vec\n",
            "  Cloning https://github.com/samoturk/mol2vec to /tmp/pip-req-build-alzttblu\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/samoturk/mol2vec /tmp/pip-req-build-alzttblu\n",
            "  Resolved https://github.com/samoturk/mol2vec to commit 850d944d5f48a58e26ed0264332b5741f72555aa\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mol2vec==0.1) (1.26.4)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from mol2vec==0.1) (4.3.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mol2vec==0.1) (4.66.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from mol2vec==0.1) (1.4.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from mol2vec==0.1) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mol2vec==0.1) (3.8.0)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (from mol2vec==0.1) (7.34.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from mol2vec==0.1) (0.13.2)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim->mol2vec==0.1) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->mol2vec==0.1) (7.0.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython->mol2vec==0.1) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from IPython->mol2vec==0.1) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython->mol2vec==0.1) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython->mol2vec==0.1) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython->mol2vec==0.1) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython->mol2vec==0.1) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython->mol2vec==0.1) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython->mol2vec==0.1) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython->mol2vec==0.1) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython->mol2vec==0.1) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mol2vec==0.1) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mol2vec==0.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mol2vec==0.1) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mol2vec==0.1) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mol2vec==0.1) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mol2vec==0.1) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mol2vec==0.1) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mol2vec==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->mol2vec==0.1) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->mol2vec==0.1) (2024.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython->mol2vec==0.1) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython->mol2vec==0.1) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->mol2vec==0.1) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mol2vec==0.1) (1.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim->mol2vec==0.1) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import rdkit\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, Descriptors\n",
        "from rdkit.Chem import PandasTools\n",
        "from rdkit.Chem.rdmolops import RemoveHs\n",
        "from rdkit.Chem import rdmolfiles\n",
        "from rdkit.Chem import rdMolDescriptors\n",
        "from rdkit import DataStructs\n",
        "\n",
        "import selfies as sf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# For handling the embedding layer and Mol2Vec\n",
        "from gensim.models import word2vec\n",
        "from gensim.models import Word2Vec\n",
        "import deepchem as dc\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoUcwKL-ZFYk",
        "outputId": "96001ede-facc-4b91-e9d6-613c2d0e4571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for SPS. Feature removed!\n",
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for AvgIpc. Feature removed!\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
            "WARNING:deepchem.models.torch_models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/usr/local/lib/python3.10/dist-packages/deepchem/models/torch_models/__init__.py)\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
            "WARNING:deepchem.models:Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import selfies as sf\n",
        "\n",
        "def selfies_to_molecule(selfies_string):\n",
        "    try:\n",
        "        return Chem.MolFromSmiles(sf.decoder(selfies_string));\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n"
      ],
      "metadata": {
        "id": "_eWn0a3dXOcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import word2vec\n",
        "model = word2vec.Word2Vec.load('model_300dim.pkl')\n",
        "from mol2vec.features import mol2alt_sentence, mol2sentence, MolSentence, DfVec, sentences2vec\n",
        "from gensim.models import word2vec\n",
        "\n",
        "def patched_sentences2vec(sentences, keyed_vectors, unseen=None):\n",
        "    \"\"\"\n",
        "    Convert a list of sentences into a list of vectors, using the KeyedVectors from Gensim 4.x.\n",
        "    \"\"\"\n",
        "    keys = set(keyed_vectors.key_to_index.keys())\n",
        "    vec = []\n",
        "    for sentence in sentences:\n",
        "        sentence_vec = []\n",
        "        for word in sentence:\n",
        "            if word in keys:\n",
        "                sentence_vec.append(keyed_vectors[word])\n",
        "            elif unseen is not None and unseen in keys:\n",
        "                sentence_vec.append(keyed_vectors[unseen])\n",
        "        vec.append(np.mean(sentence_vec, axis=0) if sentence_vec else np.zeros(keyed_vectors.vector_size))\n",
        "    return np.array(vec)"
      ],
      "metadata": {
        "id": "dL9EcMaSXTF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def molecule_to_vec(mol):\n",
        "  sentence = MolSentence(mol2alt_sentence(mol, 1))\n",
        "  mol_Vec = DfVec(patched_sentences2vec(sentence, model.wv, unseen='UNK'))\n",
        "  X = np.array(mol_Vec.vec)\n",
        "  return X"
      ],
      "metadata": {
        "id": "z8BBxpmWXyuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U_lHG4FjY8Ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 3. Generate Trajectories\n",
        "# ============================\n",
        "\n",
        "\n",
        "def generate_trajectory(policy_model, tokenizer, reward_model):\n",
        "    alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "    ### Instruction:\n",
        "    {}\n",
        "\n",
        "    ### Input:\n",
        "    {}\n",
        "\n",
        "    ### Response:\n",
        "    {}\"\"\"\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Move models to the same device\n",
        "    policy_model.to(device)\n",
        "    reward_model.to(device)\n",
        "\n",
        "    # Number of examples to generate\n",
        "    num_examples = 1\n",
        "    batch_size = 1  # Adjust batch size based on your GPU memory\n",
        "\n",
        "    responses = []\n",
        "\n",
        "    def is_valid_selfies(selfies_str):\n",
        "        try:\n",
        "            smiles = sf.decoder(selfies_str)\n",
        "            from rdkit import Chem\n",
        "            mol = Chem.MolFromSmiles(smiles)\n",
        "            return mol is not None\n",
        "        except Exception:\n",
        "            return False\n",
        "\n",
        "    num_batches = num_examples // batch_size\n",
        "    for batch_num in range(num_batches):\n",
        "        print(f\"Generating batch {batch_num + 1}/{num_batches}\")\n",
        "\n",
        "        # Prepare prompts for the batch\n",
        "        prompts = [alpaca_prompt.format(\n",
        "            \"You love and excel generating SELFIES strings for drug-like molecules. Generate a SELFIES representation of a molecule that could inhibit the JAK2 protein\",\n",
        "            \"\",\n",
        "            \"\",\n",
        "        ) for _ in range(batch_size)]\n",
        "\n",
        "        # Tokenize inputs and move tensors to device\n",
        "        inputs = tokenizer(prompts, return_tensors='pt', padding=True, truncation=True).to(device)\n",
        "\n",
        "        outputs = policy_model.generate(\n",
        "            input_ids=inputs['input_ids'],\n",
        "            attention_mask=inputs['attention_mask'],\n",
        "            max_new_tokens=256,\n",
        "            num_return_sequences=1,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "        )\n",
        "\n",
        "        # Decode outputs\n",
        "        for i in range(batch_size):\n",
        "            input_length = inputs['input_ids'][i].shape[0]\n",
        "            generated_tokens = outputs[i][input_length:]\n",
        "            response_text = tokenizer.decode(generated_tokens, skip_special_tokens=True).strip()\n",
        "            responses.append(response_text)\n",
        "\n",
        "    valid_responses = []\n",
        "    for idx, response in enumerate(responses):\n",
        "        if is_valid_selfies(response):\n",
        "            valid_responses.append({'selfies': response})\n",
        "            print(response)\n",
        "        else:\n",
        "            print(f\"Invalid SELFIES at index {idx}: {response}\")\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    reward = 0\n",
        "    df = pd.DataFrame(valid_responses, columns=['selfies'])\n",
        "\n",
        "    def selfies_to_smiles(selfies_string):\n",
        "        try:\n",
        "            return sf.decoder(selfies_string)\n",
        "        except Exception as e:\n",
        "            return f\"Error: {e}\"\n",
        "\n",
        "    # Apply transformations (ensure no tensors leave GPU where possible)\n",
        "    df['SMILES'] = df['selfies'].apply(selfies_to_smiles)\n",
        "    df['mol'] = df['SMILES'].apply(lambda x: Chem.MolFromSmiles(x))\n",
        "    df['sentence'] = df.apply(lambda x: MolSentence(mol2alt_sentence(x['mol'], 1)), axis=1)\n",
        "    df['mol2vec'] = [\n",
        "        DfVec(x) for x in patched_sentences2vec(df['sentence'], model.wv, unseen='UNK')\n",
        "    ]\n",
        "\n",
        "    X = np.array([x.vec for x in df['mol2vec']])\n",
        "    x_test_tensor = torch.tensor(X, dtype=torch.float32).to(device)  # Move tensor to device\n",
        "\n",
        "    x_test_tensor = x_test_tensor.unsqueeze(1)  # Add sequence length dimension\n",
        "    y_pred_test = reward_model(x_test_tensor)\n",
        "\n",
        "    y_array = y_pred_test.detach().cpu().numpy()  # Ensure numpy conversion happens on CPU\n",
        "\n",
        "    reward = np.mean(y_array)\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": inputs.input_ids,\n",
        "        \"generated_ids\": outputs,\n",
        "        \"reward\": reward\n",
        "    }\n",
        "\n",
        "generate_trajectory(policy_model, tokenizer, reward_model)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "XPHUwnHQU_I1",
        "outputId": "1fb0e21c-36fb-405c-aa8f-f0e77d5c706c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'policy_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f81bbc897b90>\u001b[0m in \u001b[0;36m<cell line: 113>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m     }\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m \u001b[0mgenerate_trajectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'policy_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# 4. PPO Class\n",
        "# ============================\n",
        "class PPO:\n",
        "\n",
        "    def __init__(self, policy_model, reward_model, lr= 1.41 , gamma=0.99, eps_clip=0.2):\n",
        "        self.policy_model = policy_model\n",
        "        self.reward_model = reward_model\n",
        "        self.optimizer = torch.optim.Adam(policy_model.parameters(), lr=lr)\n",
        "        self.gamma = gamma  # Discount factor\n",
        "        self.eps_clip = eps_clip  # Clipping parameter\n",
        "\n",
        "    def compute_advantages(self, rewards, values):\n",
        "        rewards = torch.tensor(rewards, dtype=torch.float32).to(\"cpu\")\n",
        "        values = torch.tensor(values, dtype=torch.float32).to(\"cpu\")\n",
        "\n",
        "        if len(rewards) != len(values):  # Validate shapes\n",
        "           raise ValueError(f\"Rewards and values must have the same length, but got {len(rewards)} and {len(values)}.\")\n",
        "\n",
        "        advantages = torch.zeros_like(rewards).to(\"cpu\")  # Initialize a tensor for advantages\n",
        "        gae = 0\n",
        "        for t in reversed(range(len(rewards))):\n",
        "            delta = rewards[t] + self.gamma * (values[t + 1] if t + 1 < len(values) else 0) - values[t]\n",
        "            gae = delta + self.gamma * gae\n",
        "            advantages[t] = gae\n",
        "        return advantages\n",
        "\n",
        "    def update(self, trajectories):\n",
        "        for trajectory in trajectories:\n",
        "            rewards = trajectory[\"reward\"]  # Should be a list or 1-D tensor\n",
        "            generated_ids = trajectory[\"generated_ids\"].to(\"cpu\")\n",
        "            inputs = trajectory[\"input_ids\"].to(\"cpu\")\n",
        "\n",
        "            # Compute log probs and values\n",
        "            outputs = self.policy_model(inputs)\n",
        "            logits = outputs.logits  # Shape: (batch_size, seq_len, vocab_size)\n",
        "            log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n",
        "\n",
        "            # Use only the last timestep's logits for value estimation\n",
        "            values = logits[:, -1, :].max(dim=-1)[0]  # Shape: (batch_size,)\n",
        "\n",
        "            # Ensure rewards is tensor and 1-D\n",
        "            rewards = torch.tensor(rewards, dtype=torch.float32).flatten().to(\"cpu\")\n",
        "            if len(rewards) != values.size(0):  # Check compatibility\n",
        "                raise ValueError(f\"Mismatch in rewards and values shapes: {len(rewards)} vs {values.size(0)}\")\n",
        "\n",
        "            # Compute advantages\n",
        "            advantages = self.compute_advantages(rewards, values)\n",
        "\n",
        "            # PPO objective\n",
        "            ratio = torch.exp(log_probs - log_probs.detach())  # Importance ratio\n",
        "            clipped_ratio = torch.clamp(ratio, 1 - self.eps_clip, 1 + self.eps_clip)\n",
        "            loss = -torch.min(ratio * advantages, clipped_ratio * advantages).mean()\n",
        "\n",
        "            # Optimize\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n"
      ],
      "metadata": {
        "id": "1CVWlu51VCXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# ============================\n",
        "# 5. Training Loop\n",
        "# ============================\n",
        "\n",
        "ppo = PPO(policy_model, reward_model)\n",
        "\n",
        "num_epochs = 16\n",
        "torch.cuda.empty_cache()  # Clear any residual memory at the start\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()  # Mixed precision scaler\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    trajectories = []\n",
        "    trajectory = generate_trajectory(policy_model, tokenizer, reward_model)\n",
        "    trajectories.append(trajectory)\n",
        "\n",
        "    ppo.update(trajectories)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NG3hhnHVEgP",
        "outputId": "845caf6c-2771-4f68-fdce-2028ca6a9130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating batch 1/1\n",
            "[C][C][C][Branch1][Ring1][#C][C][N][C][=C][Branch1][Branch1][C][=N][Ring1][Branch1][C][=N][C][=Branch1][O][=C][N][N][=C][C][=C][Ring1][=Branch1][C][Branch1][C][F][Branch1][C][F][F][C][=C][Ring1][#Branch1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[21:34:16] DEPRECATION WARNING: please use MorganGenerator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "policy_model.save_pretrained(\"PPOJak2\") # Local saving\n",
        "tokenizer.save_pretrained(\"PPOJak2\")\n",
        "\n",
        "model_name_on_hub = \"PPOJak2\"\n",
        "model.push_to_hub(model_name_on_hub)\n",
        "tokenizer.push_to_hub(model_name_on_hub)"
      ],
      "metadata": {
        "id": "UdHaj6ShVEtq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}